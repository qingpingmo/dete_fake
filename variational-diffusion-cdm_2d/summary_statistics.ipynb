{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import matplotlib as mpl\n",
    "\n",
    "import model.networks as networks\n",
    "import model.vdm_model as vdm_model\n",
    "import utils.utils as utils\n",
    "import data.constants as constants\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['science', 'vibrant'])\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dataset = 'Astrid',\n",
    "        cropsize = 256,\n",
    "        gamma_min = -13.3,\n",
    "        gamma_max = 13.3,\n",
    "        embedding_dim = 48,\n",
    "        norm_groups = 8,\n",
    "        use_fourier_features = False,\n",
    "        add_attention = True,\n",
    "        noise_schedule = 'learned_linear',\n",
    "        n_blocks = 4\n",
    "):\n",
    "    vdm = vdm_model.LightVDM(\n",
    "            score_model=networks.UNetVDM(\n",
    "                gamma_min=gamma_min,\n",
    "                gamma_max=gamma_max,\n",
    "                embedding_dim=embedding_dim,\n",
    "                norm_groups=norm_groups,\n",
    "                n_blocks=n_blocks,\n",
    "                add_attention=add_attention,\n",
    "                use_fourier_features=use_fourier_features\n",
    "            ),\n",
    "            dataset=dataset,\n",
    "            gamma_min=gamma_min,\n",
    "            gamma_max=gamma_max,\n",
    "            image_shape=(1,cropsize,cropsize),\n",
    "            noise_schedule=noise_schedule,\n",
    "        )\n",
    "    vdm = vdm.to(device=device)\n",
    "    vdm = vdm.eval()\n",
    "    \n",
    "    ckpt = '/opt/data/private/wangjuntong/code/variational-diffusion-cdm/debiasing/a1fcfabec6d140719e68c3bb3643c110/checkpoints/epoch=38-step=39000-val_loss=0.037.ckpt'\n",
    "    state_dict=torch.load(ckpt)[\"state_dict\"]\n",
    "    vdm.load_state_dict(state_dict)\n",
    "    return vdm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdm = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mass_mstar = np.load('Maps_Mtot_Nbody_Astrid_CV_z=0.00.npy')\n",
    "mass_cdm = np.load('Maps_Mtot_Astrid_CV_z=0.00.npy')\n",
    "mass_mstar = np.log10(mass_mstar+1)\n",
    "mass_cdm = np.log10(mass_cdm)\n",
    "\n",
    "mean_input = constants.norms['Astrid'][0]\n",
    "std_input = constants.norms['Astrid'][1]\n",
    "mean_target = constants.norms['Astrid'][2]\n",
    "std_target = constants.norms['Astrid'][3]\n",
    "\n",
    "mass_mstar_normed = torch.Tensor((mass_mstar - mean_input) / std_input).unsqueeze(1).unsqueeze(1)\n",
    "mass_cdm_normed = torch.Tensor((mass_cdm - mean_target) / std_target).unsqueeze(1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_size = 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(conditioning, batch_size=10, n=10):\n",
    "\n",
    "    star = conditioning[0]\n",
    "    star_fields = star.expand(batch_size, star.shape[0], star.shape[1], star.shape[2])\n",
    "\n",
    "    maps = [] # 10 tensors of shape ([10, 1, img_shape, img_shape])\n",
    "    # draw n samples with the same conditioning\n",
    "    for _ in range(n):\n",
    "        sample = vdm.draw_samples(\n",
    "            conditioning=star_fields,\n",
    "            batch_size=batch_size,\n",
    "            n_sampling_steps=vdm.hparams.n_sampling_steps,\n",
    "            )\n",
    "        maps.append(sample)\n",
    "        \n",
    "    return maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_fiducial_normed = torch.vstack(\n",
    "    generate_samples(\n",
    "        conditioning=mass_mstar_normed[idx].to(device), \n",
    "        batch_size=20, \n",
    "        n=5,\n",
    "    )\n",
    ")\n",
    "generated_fiducial = generated_fiducial_normed * std_target + mean_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, fiducial_pk = utils.compute_pk(10**mass_cdm[idx][None,None],)\n",
    "k, stars_pk = utils.compute_pk(10**mass_mstar[idx][None,None]-1)\n",
    "k, cross_stars_true = utils.compute_pk(10**mass_mstar[idx][None,None], 10**mass_cdm[idx][None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_pk, cross_stars_pk, cross_true_pk = [], [], []\n",
    "for sample in generated_fiducial:\n",
    "    generated_pk.append(utils.compute_pk(10**sample.cpu().numpy()[None])[1])\n",
    "    k, cross_stars_sample = utils.compute_pk(10**mass_mstar[idx][None][None]-1, 10**sample[None].cpu().numpy())\n",
    "    cross_stars_pk.append(cross_stars_sample)\n",
    "    k, cross_true_sample = utils.compute_pk(10**mass_cdm[idx][None][None], 10**sample[None].cpu().numpy())\n",
    "    cross_true_pk.append(cross_true_sample)\n",
    "generated_pk = torch.stack(generated_pk)\n",
    "cross_stars_pk = torch.stack(cross_stars_pk)\n",
    "cross_true_pk = torch.stack(cross_true_pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mean = torch.mean(generated_fiducial, dim=0).squeeze().detach().cpu().numpy()\n",
    "post_std = torch.std(generated_fiducial, dim=0).squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "z_score = (mass_cdm[idx].squeeze() - post_mean) / post_std\n",
    "diverging_norm = TwoSlopeNorm(vmin=z_score.min(), vcenter=0, vmax=z_score.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(10,6))\n",
    "fig.subplots_adjust(wspace=0.1)\n",
    "axes = axes.flatten()\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 11,\n",
    "    'legend.loc': 'upper right',\n",
    "    'legend.fontsize': 6\n",
    "    })\n",
    "img = axes[0].imshow(mass_mstar[idx].squeeze(), cmap='copper')\n",
    "fig.colorbar(img, ax=axes[0], fraction=0.045)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['left'].set_visible(False)\n",
    "axes[0].spines['bottom'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([0., 64., 128., 192., 256.], labels=[\"0\", \"6.25\", \"12.50\", \"18.75\", \"25.00\"])\n",
    "axes[0].set_ylabel(\"Mpc/h\")        \n",
    "img = axes[1].imshow(mass_cdm[idx].squeeze(), cmap='cividis',vmin=10,vmax=14.5)\n",
    "fig.colorbar(img, ax=axes[1], fraction=0.045)\n",
    "axes[1].axis('off')\n",
    "\n",
    "img = axes[2].imshow(generated_fiducial[idx].squeeze().cpu(), cmap='cividis',vmin=10, vmax=14.5)\n",
    "fig.colorbar(img, ax=axes[2], fraction=0.045)\n",
    "axes[2].axis('off')\n",
    "\n",
    "\n",
    "img = axes[3].imshow(post_mean, cmap='cividis', vmin=10,vmax=14.5)\n",
    "cbar = fig.colorbar(img, ax=axes[3], fraction=0.045)\n",
    "axes[3].axis('off')\n",
    "\n",
    "img = axes[4].imshow(post_std, cmap='cividis', )#norm=LogNorm())\n",
    "cbar = fig.colorbar(img, ax=axes[4], fraction=0.045)\n",
    "\n",
    "axes[4].axis('off')\n",
    "img = axes[5].imshow(z_score.squeeze(), cmap='coolwarm', norm=diverging_norm)\n",
    "cbar = fig.colorbar(img, ax=axes[5], fraction=0.045)\n",
    "axes[5].axis('off')\n",
    "axes[0].set_title(r\"$M_{\\mathrm{star}}$\")\n",
    "axes[1].set_title(r\"$M_{\\mathrm{CDM}}$ Truth\")\n",
    "axes[2].set_title(r\"$M_{\\mathrm{CDM}}$ Sample\")\n",
    "axes[3].set_title(r\"$M_{\\mathrm{CDM}}$ Posterior Mean\")\n",
    "axes[4].set_title(r\"$M_{\\mathrm{CDM}}$ Posterior Std\")\n",
    "axes[5].set_title(r\"$M_{\\mathrm{CDM}}$ Z-score\")\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_idx = np.unique(np.arange(len(k))[np.logspace(0,np.log10(len(k)),50).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(10,3))\n",
    "fig.subplots_adjust(wspace=0.1)\n",
    "axes = axes.flatten()\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 11,\n",
    "    'legend.loc': 'upper right',\n",
    "    'legend.fontsize': 6\n",
    "    })\n",
    "\n",
    "\n",
    "cdm_bins = np.linspace(10,17.,80)\n",
    "cdm_bins_c = 0.5*(cdm_bins[1:] + cdm_bins[:-1])\n",
    "star_bins = np.linspace(7.5,13,30)\n",
    "star_bins_c = 0.5*(star_bins[1:] + star_bins[:-1])\n",
    "hist_generated = []\n",
    "for i in range(len(generated_fiducial)):\n",
    "    gen_hist, _ = np.histogram(generated_fiducial[i].squeeze().cpu().numpy().flatten(), bins=cdm_bins, density=True,)\n",
    "    hist_generated.append(gen_hist)\n",
    "axes[0].fill_between(\n",
    "    cdm_bins_c, \n",
    "    np.percentile(hist_generated, 10, axis=0), \n",
    "    np.percentile(hist_generated, 90, axis=0), \n",
    "    color='#709bb5', label='Sample CDM',\n",
    "    alpha=0.2,\n",
    ")\n",
    "axes[0].plot(cdm_bins_c,np.histogram(mass_cdm[idx].squeeze().flatten(), bins=cdm_bins, density=True)[0],  color='#4c4173', label=\"Truth CDM\", )\n",
    "axes[0].plot(star_bins_c,np.histogram(mass_mstar[idx].squeeze().flatten(), bins=star_bins, density=True)[0],  color='#C09465', label=\"Stars\", )\n",
    "axes[0].set_title(r'$M_{\\mathrm{CDM}}$ Density PDF') \n",
    "axes[0].set_xlabel(r'$\\mathrm{log}_{10} \\Sigma$ ' + '$[M_{\\odot} h^{-1} ( h^{-1} \\mathrm{Mpc})^{-2}]$')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "axes[1].fill_between(\n",
    "    k[k_idx],\n",
    "    np.percentile(generated_pk[:, k_idx].cpu().numpy(), 10,axis=0),\n",
    "    np.percentile(generated_pk[:, k_idx].cpu().numpy(), 90,axis=0),\n",
    "    color='#709bb5', alpha=0.2, label='Sample CDM'\n",
    ")\n",
    "axes[1].loglog(k[k_idx], fiducial_pk[k_idx] , color='#4c4173', label=\"Truth CDM\", )\n",
    "axes[1].loglog(k[k_idx], stars_pk[k_idx], color='#C09465', label=\"Stars\", )\n",
    "axes[1].set_ylabel('$P(k)$ [$h^{-2}\\mathrm{Mpc}^2$]')\n",
    "axes[1].set_xlabel('$k$ [$h \\ \\mathrm{Mpc}^{-1}$]')\n",
    "axes[1].set_title('Power Spectrum')\n",
    "axes[1].legend(fontsize=10, loc='lower left')\n",
    "\n",
    "axes[2].fill_between(\n",
    "    k[k_idx],\n",
    "    np.percentile(cross_true_pk[:, k_idx].cpu().numpy() / np.sqrt(fiducial_pk[k_idx]) / np.sqrt(generated_pk[:, k_idx].cpu()),10, axis=0),\n",
    "    np.percentile(cross_true_pk[:, k_idx].cpu().numpy() / np.sqrt(fiducial_pk[k_idx]) / np.sqrt(generated_pk[:, k_idx].cpu()),90, axis=0),\n",
    "    color='#709bb5',\n",
    "    alpha=0.2,\n",
    "    label=r'$\\langle \\text{TruthCDM} \\, \\text{SampleCDM} \\rangle$' ,\n",
    ")\n",
    "axes[2].set_xscale('log')\n",
    "axes[2].axhline(1, color='#4c4173')\n",
    "axes[2].set_ylim(0.8,1.05)\n",
    "axes[2].set_ylabel('Cross correlation coefficient')\n",
    "axes[2].set_xlabel('$k$ [$h \\ \\mathrm{Mpc}^{-1}$]')\n",
    "axes[2].set_title('Cross correlations')\n",
    "axes[2].legend(fontsize=10, loc='lower left')\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunbird",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
